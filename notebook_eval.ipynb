{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdd5d440",
   "metadata": {},
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a591cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.collections import PatchCollection\n",
    "import pickle\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "plt.show() # need to call show so will update default params above\n",
    "# color blind friendly colors\n",
    "# https://gist.github.com/thriveth/8560036\n",
    "color_blinds = {\n",
    "    'blue':   [55/255,  126/255, 184/255],  #377eb8 \n",
    "    'orange': [255/255, 127/255, 0/255],    #ff7f00\n",
    "    'green':  [77/255,  175/255, 74/255],   #4daf4a\n",
    "    'pink':   [247/255, 129/255, 191/255],  #f781bf\n",
    "    'brown':  [166/255, 86/255,  40/255],   #a65628\n",
    "    'purple': [152/255, 78/255,  163/255],  #984ea3\n",
    "    'gray':   [153/255, 153/255, 153/255],  #999999\n",
    "    'red':    [228/255, 26/255,  28/255],   #e41a1c\n",
    "    'yellow': [222/255, 222/255, 0/255]     #dede00\n",
    "} \n",
    "color_blinds_list = [color_blinds[color] for color in color_blinds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6828cf5-8596-4443-9e92-57b1440eaaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'local/runs/example_dqn/'\n",
    "\n",
    "train_log_path = train_path + 'log.txt'\n",
    "train_configuration_path = train_path + 'configuration.json'\n",
    "train_states_path = train_path + 'states/'\n",
    "\n",
    "test_path = train_path + 'test/'\n",
    "test_log_path = test_path + 'log.txt'\n",
    "test_configuration_path = test_path + 'configuration.json'\n",
    "test_states_path = test_path + 'states/'\n",
    "\n",
    "model_path = train_path + 'model'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade830ea-40be-4283-8098-39156bd6b66d",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ec0a3b-df81-48a6-b6de-01ee38b0175a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_configuration = json.load(open(train_configuration_path, 'r'))\n",
    "test_configuration = json.load(open(test_configuration_path, 'r'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a45fd92-33b3-4798-a0eb-5b442de08b60",
   "metadata": {},
   "source": [
    "# access neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f591801-7d47-452d-8090-148b1aec73a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DQN as sb3DQN\n",
    "mdl = sb3DQN.load(model_path)\n",
    "mdl.policy\n",
    "\n",
    "# from stable_baselines3 import TD3 as sb3TD3\n",
    "# mdl = sb3TD3.load(model_path)\n",
    "# mdl.actor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4c01db",
   "metadata": {},
   "source": [
    "# read states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32774073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json files output with all string key names\n",
    "# process so that the evaluation dictionary structure is such:\n",
    "    # episode # - int\n",
    "        # step # - int\n",
    "            # state - dictionary of misc key, value pairs for that state\n",
    "def process_episodes(json_evaluation):\n",
    "    nEpisodes = len(json_evaluation)\n",
    "    episodes = [None] * nEpisodes\n",
    "    episode_idx = 0\n",
    "    for episode_str in json_evaluation:\n",
    "        if 'episode_' not in episode_str:\n",
    "            continue\n",
    "        json_episode = json_evaluation[episode_str]\n",
    "        nSteps = len(json_episode)\n",
    "        states = [None] * nSteps\n",
    "        for step_str in json_episode:\n",
    "            step_num = int(step_str.split('_')[1])\n",
    "            state = json_episode[step_str]\n",
    "            states[step_num] = state\n",
    "        episodes[episode_idx] = states\n",
    "        episode_idx += 1\n",
    "    return episodes\n",
    "def read_evaluations(evaluation_folder):\n",
    "    evaluation_files = [file for file in os.listdir(evaluation_folder) if 'states' in file]\n",
    "    nEvaluations = len(evaluation_files)\n",
    "    evaluations = [None] * nEvaluations\n",
    "    for evaluation_file in evaluation_files:\n",
    "        if '.json' not in evaluation_file:\n",
    "            continue\n",
    "        epoch = int(evaluation_file.split('.')[0].split('_')[-1])\n",
    "        #print(evaluation_file, epoch)\n",
    "        json_evaluation = json.load(open(evaluation_folder + evaluation_file, 'r'))\n",
    "        episodes = process_episodes(json_evaluation)\n",
    "        evaluations[epoch] = episodes\n",
    "    return evaluations\n",
    "# architecture for evaluations:\n",
    "# evaluations - list of episodes (indexed of evaluation number) - 0 idx is first evaluation\n",
    "    # episodes - list of states (indexed by step number)\n",
    "        # states - dict of (key, value) pairs for state at all_evaluations[instance][evaluation][episode][step]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9c8991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read evaluations from each instance\n",
    "# each instance is a sub folder from parent with which this eval notebook is in\n",
    "instances = [\n",
    "    train_path + 'states',\n",
    "    test_path + 'states',\n",
    "    ]\n",
    "all_evaluations = {}\n",
    "for instance in instances:\n",
    "    all_evaluations[instance] = read_evaluations(instance + '/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50f0efa-cace-4883-85c8-7ed8481ba409",
   "metadata": {},
   "source": [
    "# path accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f3adb1-2332-4b61-8ae2-21050fc0927f",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_instances = [\n",
    "    #train_path + 'train_states',\n",
    "    test_path + 'states',\n",
    "]\n",
    "goals = []\n",
    "for instance in acc_instances:\n",
    "    for set_num, episodes in enumerate(all_evaluations[instance]):\n",
    "        for episode, states in enumerate(episodes):\n",
    "            final_step = states[-1]\n",
    "            goals.append(final_step['reached_goal'])\n",
    "print(f'total accuracy = {np.round(100*np.mean(goals),2)}%')\n",
    "\n",
    "# check against astar paths\n",
    "path_idxs = pickle.load(open(test_path+'_static_path_idxs.p', 'rb'))\n",
    "astar_paths = pickle.load(open('astar_paths/Blocks_2d_test.p', 'rb'))\n",
    "linearity_bounds = astar_paths['linearity_bounds']\n",
    "nonlinearity_bounds = astar_paths['nonlinearity_bounds']\n",
    "goal_map = np.zeros([len(linearity_bounds), len(nonlinearity_bounds)]).astype(float)\n",
    "total_map = np.zeros([len(linearity_bounds), len(nonlinearity_bounds)]).astype(float)\n",
    "def get_bin(linearity, nonlinearity):\n",
    "    for i in range(len(linearity_bounds)-1):\n",
    "        if linearity < linearity_bounds[i+1]:\n",
    "            for j in range(len(nonlinearity_bounds)-1):\n",
    "                if nonlinearity < nonlinearity_bounds[j+1]:\n",
    "                    return i, j\n",
    "for idx, path_idx in enumerate(path_idxs):\n",
    "    path = astar_paths['paths'][path_idx]\n",
    "    linearity = astar_paths['linearitys'][path_idx]\n",
    "    nonlinearity = astar_paths['nonlinearitys'][path_idx]\n",
    "    goal = goals[idx]\n",
    "    i, j = get_bin(linearity, nonlinearity)\n",
    "    goal_map[i, j] += goal\n",
    "    total_map[i, j] += 1\n",
    "goal_map[total_map <= 0] = np.nan\n",
    "total_map[total_map <= 0] = np.nan\n",
    "acc_map = goal_map / total_map\n",
    "fig, ax = plt.subplots()\n",
    "cbar = ax.imshow(acc_map.T, origin='lower')\n",
    "fig.colorbar(cbar)\n",
    "plt.title('Path Accuracy')\n",
    "delta = 4\n",
    "ax.set_xticks([i for i in range(0, len(linearity_bounds), delta)], [np.round(linearity_bounds[i],2) for i in range(0, len(linearity_bounds), delta)], rotation=45)\n",
    "ax.set_yticks([i for i in range(0, len(nonlinearity_bounds), delta)], [np.round(nonlinearity_bounds[i],2) for i in range(0, len(nonlinearity_bounds), delta)], rotation=45)\n",
    "plt.xlabel('Eucledian Distance to Goal [m]')\n",
    "plt.ylabel('Number of Rotation Actions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713499b7",
   "metadata": {},
   "source": [
    "# map visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f3fda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rooftops_dict = pickle.load(open('rooftops/Blocks.p', 'rb'))\n",
    "rooftops_arr = []\n",
    "for key in rooftops_dict:\n",
    "    row = []\n",
    "    for key2 in rooftops_dict[key]:\n",
    "        row.append(rooftops_dict[key][key2])\n",
    "    rooftops_arr.append(row)\n",
    "rooftops_arr = np.array(rooftops_arr)\n",
    "x_min = list(rooftops_dict.keys())[0]\n",
    "y_min = list(rooftops_dict[x_min].keys())[0]\n",
    "def plot_map(fig, ax):\n",
    "    interval = 40\n",
    "    im = ax.imshow(rooftops_arr, cmap='hot', interpolation='nearest', origin='lower')\n",
    "    cbar = fig.colorbar(im, shrink=0.8)\n",
    "    cbar.ax.get_yaxis().labelpad = 25\n",
    "    cbar.ax.set_ylabel('z [meters]', rotation=270)\n",
    "    ax.set_xticks([i for i in range(0, len(rooftops_arr[0]), interval)], \n",
    "              [y_min + i for i in range(0, len(rooftops_arr[0]), interval)], rotation=90)\n",
    "    ax.set_yticks([i for i in range(0, len(rooftops_arr), interval)], \n",
    "              [x_min + i for i in range(0, len(rooftops_arr), interval)])\n",
    "    ax.set_ylabel('x [meters]')\n",
    "    ax.set_xlabel('y [meters')\n",
    "    ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef0113c-6417-44a5-b933-acebb9d02109",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plot_map(fig, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b1e4f4-c143-4d60-b999-cb1043d7fa44",
   "metadata": {},
   "source": [
    "# analyze training metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051de3b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# process final sate values\n",
    "final_variables = {instance:{} for instance in instances}\n",
    "for instance in instances:\n",
    "    for set_num, episodes in enumerate(all_evaluations[instance]):\n",
    "        for episode, states in enumerate(episodes):\n",
    "            for step, state in enumerate(states):\n",
    "                if step == 0:\n",
    "                    if 'goal_distance' not in final_variables[instance]:\n",
    "                        final_variables[instance]['goal_distance'] = {}\n",
    "                    if episode not in final_variables[instance]['goal_distance']:\n",
    "                        final_variables[instance]['goal_distance'][episode] = []\n",
    "                    drone_position = np.array(state['drone_position'])\n",
    "                    goal_position = np.array(state['goal_position'])\n",
    "                    goal_distance = np.linalg.norm(goal_position - drone_position)\n",
    "                    final_variables[instance]['goal_distance'][episode].append(goal_distance)\n",
    "                    continue\n",
    "            final_state = states[-1]\n",
    "            for variable in final_state:\n",
    "                if variable not in final_variables[instance]:\n",
    "                    final_variables[instance][variable] = {}\n",
    "                if episode not in final_variables[instance][variable]:\n",
    "                    final_variables[instance][variable][episode] = []\n",
    "                final_variables[instance][variable][episode].append(final_state[variable])\n",
    "\n",
    "# architecture of final_variables:\n",
    "# instance - str name\n",
    "    # variable - str name\n",
    "        # episode - int number\n",
    "            # final values - list of final values with increased # of training evaluations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0f8520",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# PLOT RESULTS VERSUS TRAINING TIME\n",
    "results_instances = [\n",
    "    train_path + 'states',\n",
    "]\n",
    "# select which state variables to fetch\n",
    "numerical_variables = [\n",
    "    #'nSteps', \n",
    "    'total_reward', \n",
    "    'goal_distance',\n",
    "]\n",
    "string_variables = [\n",
    "    #'transcribed_action', \n",
    "    'termination_reason',\n",
    "]\n",
    "all_variables = numerical_variables + string_variables\n",
    "\n",
    "shorten = {\n",
    "    'termination_reason':'termination',\n",
    "}\n",
    "\n",
    "# take mean values\n",
    "for variable in all_variables:\n",
    "    for instance in results_instances:\n",
    "        if variable not in shorten:\n",
    "            shorten[variable] = variable\n",
    "        plot_name = instance + '_' + variable\n",
    "        \n",
    "        values = {}\n",
    "        for episode in final_variables[instance][variable]:\n",
    "            for evaluation in range(len(final_variables[instance][variable][episode])):\n",
    "                if evaluation not in values:\n",
    "                    values[evaluation] = []\n",
    "                values[evaluation].append(final_variables[instance][variable][episode][evaluation])\n",
    "\n",
    "        if variable in numerical_variables:\n",
    "            aggregates = []\n",
    "            nEpisodes = len(final_variables[instance][variable])\n",
    "            for evaluation in values:\n",
    "                aggregates.append(sum(values[evaluation])/len(values[evaluation]))\n",
    "            plt.title(instance)\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel(variable)\n",
    "            plt.plot(aggregates)\n",
    "            plt.tight_layout()\n",
    "            #fig = plt.gcf()\n",
    "            #fig.set_size_inches(8, 4)\n",
    "            #plt.savefig(plot_dir + plot_name + '.png')\n",
    "            plt.show()\n",
    "\n",
    "        if variable in string_variables:\n",
    "            fig = plt.gcf()\n",
    "            fig.set_size_inches(4, 4)\n",
    "            aggregates = {}\n",
    "            for evaluation in values:\n",
    "                for name in values[evaluation]:\n",
    "                    if name not in aggregates:\n",
    "                        aggregates[name] = {}\n",
    "                    if evaluation not in aggregates[name]:\n",
    "                        aggregates[name][evaluation] = 0\n",
    "                    aggregates[name][evaluation] += 1   \n",
    "            df_data = {'count':[], shorten[variable]:[], 'epoch':[]}\n",
    "            for name in aggregates:\n",
    "                for evaluation in values:\n",
    "                    if evaluation not in aggregates[name]:\n",
    "                        aggregates[name][evaluation] = 0\n",
    "                    count = aggregates[name][evaluation]\n",
    "                    df_data['count'].append(count)\n",
    "                    df_data[shorten[variable]].append(name[0])\n",
    "                    df_data['epoch'].append(evaluation)\n",
    "            df = pd.DataFrame(df_data)\n",
    "            heatmap_data = pd.pivot_table(df, values='count', index=[shorten[variable]], columns='epoch')\n",
    "            sns.heatmap(heatmap_data, cbar=False)\n",
    "            #plt.imshow(heatmap_data.to_numpy())\n",
    "            plt.title(instance)\n",
    "            plt.tight_layout()\n",
    "            #plt.savefig(plot_dir + plot_name + '.png')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e360234d-742f-4a3b-aa71-ec4a4b8b31da",
   "metadata": {},
   "source": [
    "# view learned navigation paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73bcfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT PATHS (this is alot so you probably want to limit which ones to visualize\n",
    "gamma = test_configuration['components']['Model']['gamma']\n",
    "goal_tolerance = 2\n",
    "path_instances = [\n",
    "    #train_path + 'train_states',\n",
    "    test_path + 'states',\n",
    "]\n",
    "for instance in path_instances:\n",
    "    evaluations = all_evaluations[instance]\n",
    "    for set_num, episodes in enumerate(evaluations):\n",
    "        paths = []\n",
    "        reward_paths = []\n",
    "        Q_paths = []\n",
    "        goals = []\n",
    "        spawns = []\n",
    "        termination_reasons = []\n",
    "        episode_numbers = []\n",
    "        # do we plot this set? (change as needed)\n",
    "        view_set = True\n",
    "        for episode, states in enumerate(episodes):\n",
    "            # get final vaules\n",
    "            final_state = episodes[episode][-1]\n",
    "            reached_goal = final_state['reached_goal']\n",
    "        if not view_set:\n",
    "            continue\n",
    "        for episode, states in enumerate(episodes):\n",
    "            # get final vaules\n",
    "            final_state = episodes[episode][-1]\n",
    "            termination_reason = final_state['termination_reason']\n",
    "            # build paths\n",
    "            path = []\n",
    "            reward_path = []\n",
    "            Q_path = []\n",
    "            episode_numbers.append(episode)\n",
    "            # get initial value\n",
    "            init_state = states[0]\n",
    "            spawn = init_state['drone_position']\n",
    "            goal = init_state['goal_position']\n",
    "            # get intermediate values\n",
    "            for step, state in enumerate(states):\n",
    "                if step == 0: continue\n",
    "                state = episodes[episode][step]\n",
    "                drone_position = state['drone_position']\n",
    "                path.append(drone_position)\n",
    "                reward = state['total_reward']\n",
    "                reward_path.append(reward)\n",
    "                # get future values from this state\n",
    "                for step2, state2 in enumerate(states[step+1:]):\n",
    "                    if step == 0: continue\n",
    "                    reward += (gamma**(step2-step)) * state2['total_reward']\n",
    "                Q_path.append(reward)\n",
    "            reward_paths.append(reward_path)\n",
    "            termination_reasons.append(termination_reason)\n",
    "            spawns.append(spawn)\n",
    "            goals.append(goal)\n",
    "            paths.append(path)\n",
    "            Q_paths.append(Q_path)\n",
    "            # plot every 8 episodes \n",
    "            if episode == len(episodes)-1 or (episode > 0 and episode%8 == 0):\n",
    "                print(set_num)\n",
    "                # subplots\n",
    "                fig, axs = plt.subplots(nrows=2, ncols=2)\n",
    "                fig.set_size_inches(16, 8)\n",
    "                # remove the underlying Axes\n",
    "                axs[0,0].remove()\n",
    "                axs[0,1].remove()\n",
    "                axs[1,0].remove()\n",
    "                axs[1,1].remove()\n",
    "                ax1 = plt.subplot2grid((2, 2), (0, 0), rowspan=2)\n",
    "                ax2 = plt.subplot2grid((2, 2), (0, 1), colspan=1)\n",
    "                ax3 = plt.subplot2grid((2, 2), (1, 1), colspan=1)\n",
    "                # PLOT DRONE PATH\n",
    "                ax1.set_title(f'Drone Path (to scale)')#' Epoch #{set_num}')\n",
    "                # show objects on map from binvox\n",
    "                plot_map(fig, ax1)\n",
    "                # legend hack\n",
    "                #ax1.scatter(-999, -999, marker='s', color=object_color) # off map just for legend\n",
    "                legend = [\n",
    "                #    'Objects'\n",
    "                ]\n",
    "                for idx in range(len(termination_reasons)):\n",
    "                    color = color_blinds_list[idx]\n",
    "                    ax1.scatter(spawns[idx][1] - y_min, spawns[idx][0] - x_min, marker='x', color=color) # spawn location\n",
    "                    termination_reason = termination_reasons[idx]\n",
    "                    legend.append('E' + str(episode_numbers[idx]) + ':' + termination_reason)\n",
    "                plt_patches = []\n",
    "                for idx in range(len(paths)):\n",
    "                    color = color_blinds_list[idx]\n",
    "                    # plot goal\n",
    "                    obj = plt.Circle((goals[idx][1] - y_min, goals[idx][0] - x_min), goal_tolerance, color=color, alpha=0.4)\n",
    "                    plt_patches.append(obj)\n",
    "                    # plot points\n",
    "                    for point in paths[idx]:\n",
    "                        # using generic quad copter size for point sizes (set this to your drone value)\n",
    "                        radius = 0.5 #* point[2]/-4\n",
    "                        if point[1] < y_min or point[0] < x_min:\n",
    "                            continue\n",
    "                        point = plt.Circle((point[1] - y_min, point[0] - x_min), radius, color=color)\n",
    "                        plt_patches.append(point)\n",
    "                    # plot end point\n",
    "                    if paths[idx][-1][1] >= y_min and paths[idx][-1][0] >= x_min:\n",
    "                        ax1.scatter(paths[idx][-1][1] - y_min, paths[idx][-1][0] - x_min, marker='*', s=64, color=color) # end location\n",
    "                map_stuff = PatchCollection(plt_patches, match_original=True)\n",
    "                ax1.add_collection(map_stuff)\n",
    "                # PLOT REWARDS\n",
    "                ax2.set_title('Reward Path')\n",
    "                #ax2.set_xlabel('Step')\n",
    "                ax2.set_ylabel('Immediate Reward')\n",
    "                for idx in range(len(reward_paths)):\n",
    "                    color = color_blinds_list[idx]\n",
    "                    ax2.plot([i+1 for i in range(len(reward_paths[idx]))], reward_paths[idx], color=color, marker='.')\n",
    "                # PLOT Q-VALUES\n",
    "                ax3.set_title('Q-value Path')\n",
    "                ax3.set_xlabel('Step')\n",
    "                ax3.set_ylabel('Accumlated Reward')\n",
    "                for idx in range(len(Q_paths)):\n",
    "                    color = color_blinds_list[idx]\n",
    "                    ax3.plot([i+1 for i in range(len(Q_paths[idx]))], Q_paths[idx], color=color, marker='.')\n",
    "                # plot legend\n",
    "                #ax2.legend(legend)\n",
    "                plt.tight_layout()\n",
    "                # Show the graph\n",
    "                #plot_name = instance + '_best_path'\n",
    "                #plt.savefig(plot_dir + plot_name + '.png')\n",
    "                plt.show()\n",
    "                # reset path arrays\n",
    "                paths = []\n",
    "                reward_paths = []\n",
    "                Q_paths = []\n",
    "                goals = []\n",
    "                spawns = []\n",
    "                termination_reasons = []\n",
    "                episode_numbers = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611c75ee",
   "metadata": {},
   "source": [
    "# view observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5914b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view specific observations\n",
    "# this example visualizes just the last episode from testing\n",
    "nTimesteps = 1 # how many steps is set to look in past from config file\n",
    "flattened_depth_size = [6,8]\n",
    "min_d = 1\n",
    "max_d = 100\n",
    "min_o = -1*math.pi\n",
    "max_o = math.pi\n",
    "min_output = 0.1\n",
    "max_output = 1\n",
    "obs_instances = [\n",
    "    #train_path + 'train_states',\n",
    "    test_path + 'states',\n",
    "]\n",
    "for instance in obs_instances:\n",
    "    # read observations\n",
    "    files = [file for file in os.listdir(instance) if 'observations' in file]\n",
    "    observations = {}\n",
    "    for file in files:\n",
    "        observation_set = np.load(instance + '/' + file, allow_pickle=True)\n",
    "        observations.update(observation_set)\n",
    "    for set_num, episodes in enumerate(all_evaluations[instance][:1]):\n",
    "        for episode, states in enumerate(episodes[:1]):\n",
    "            for step, state in enumerate(states[1:]):\n",
    "                observation_name = state['observation_name']\n",
    "                observation = observations[observation_name]\n",
    "                vLength = int(len(observation) / nTimesteps)\n",
    "                for n in range(nTimesteps):\n",
    "                    # if following the example py file on the github it has this strucutre \n",
    "                    # you may need to change how this is visualized if edited\n",
    "                    time_observation = observation[vLength*n:vLength*n+vLength]\n",
    "                    flattened_depth = np.interp(time_observation[:-2],\n",
    "                                                (min_output, max_output),\n",
    "                                                (min_d, max_d), )\n",
    "                    goal_distance = np.interp(time_observation[-2],\n",
    "                                                (min_output, max_output),\n",
    "                                                (min_d, max_d), )\n",
    "                    goal_orientation = np.interp(time_observation[-1],\n",
    "                                                (min_output, max_output),\n",
    "                                                (min_o, max_o), )\n",
    "                    print(f'{observation_name} at step={step} t={step-n} d={goal_distance} o={goal_orientation}')\n",
    "                    plt.imshow(flattened_depth.reshape(flattened_depth_size), cmap='gray')\n",
    "                    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd86977f-e8ed-4fae-818e-86595e92c493",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
