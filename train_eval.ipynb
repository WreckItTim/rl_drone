{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdd5d440",
   "metadata": {},
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a591cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.collections import PatchCollection\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from stable_baselines3 import TD3 as sb3TD3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0402e2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set plot params\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "plt.show()\n",
    "plot_dir = 'Plots/'\n",
    "if not os.path.exists(plot_dir):\n",
    "    os.mkdir(plot_dir)\n",
    "\n",
    "# uci primary colors\n",
    "uci_blue = (0/255, 62/255, 120/255)\n",
    "uci_gold = (253/255, 185/255, 19/255)\n",
    "\n",
    "# uci secondary color palette\n",
    "uci_light_blue = (106/255, 162/255, 184/255)\n",
    "uci_light_gray = (197/255, 190/255, 181/255)\n",
    "uci_dark_blue = (27/255, 61/255, 109/255)\n",
    "uci_orange = (247/255, 141/255, 45/255)\n",
    "uci_light_yellow = (247/255, 235/255, 95/255)\n",
    "uci_dark_gray = (85/255, 87/255, 89/255)\n",
    "uci_lime_green = (122/255, 184/255, 0/255)\n",
    "\n",
    "# color blind friendly colors\n",
    "# https://gist.github.com/thriveth/8560036\n",
    "color_blinds = {\n",
    "    'blue':   [55/255,  126/255, 184/255],  #377eb8 \n",
    "    'orange': [255/255, 127/255, 0/255],    #ff7f00\n",
    "    'green':  [77/255,  175/255, 74/255],   #4daf4a\n",
    "    'pink':   [247/255, 129/255, 191/255],  #f781bf\n",
    "    'brown':  [166/255, 86/255,  40/255],   #a65628\n",
    "    'purple': [152/255, 78/255,  163/255],  #984ea3\n",
    "    'gray':   [153/255, 153/255, 153/255],  #999999\n",
    "    'red':    [228/255, 26/255,  28/255],   #e41a1c\n",
    "    'yellow': [222/255, 222/255, 0/255]     #dede00\n",
    "} \n",
    "color_blinds_list = [color_blinds[color] for color in color_blinds]\n",
    "unique_markers = ['o', 's', 'p', '*', 'X', 'd']\n",
    "\n",
    "object_color = uci_blue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713499b7",
   "metadata": {},
   "source": [
    "# BINVOX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc85eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import binvox as bv\n",
    "binvox_path = 'map_voxels.binvox'\n",
    "voxels = bv.Binvox.read(binvox_path, 'dense')\n",
    "voxels_data = voxels.data\n",
    "voxels_scale = voxels.scale \n",
    "voxels_trans = voxels.translate\n",
    "voxels_res = (np.absolute(voxels_trans)) * 2 * voxels_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f3fda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_global_plt_patches = None\n",
    "\n",
    "def plot_map(axis, object_color='gray'):\n",
    "    global _global_plt_patches\n",
    "    if _global_plt_patches is None:\n",
    "        origin = voxels_data[int(voxels_data.shape[1]/2), int(voxels_data.shape[0]/2), :]\n",
    "        floor_dim = max([i for i, x in enumerate(origin) if x])\n",
    "        print(floor_dim)\n",
    "        scale = voxels_scale * 100\n",
    "        shift = voxels_trans\n",
    "        _global_plt_patches = []\n",
    "        for x in range(voxels_data.shape[0]):\n",
    "            for y in range(voxels_data.shape[1]):\n",
    "                for z in range(voxels_data.shape[2]):\n",
    "                    if voxels_data[x, y, z] and z > floor_dim:\n",
    "                        #x_loc = x - shift - scale/2 # align to left for plt.rect\n",
    "                        #y_loc = y - shift - scale/2 # align to bottom for plt.rect\n",
    "                        #patch = patches.Rectangle((x_loc, y_loc), scale, scale, color = object_color)\n",
    "                        patch = patches.Rectangle((x+shift[0], y+shift[1]), 1, 1, color = object_color)\n",
    "                        _global_plt_patches.append(patch)\n",
    "                        break\n",
    "    # add list of patches (much quicker than iteratively drawing)\n",
    "    map_stuff = PatchCollection(_global_plt_patches, match_original=True)\n",
    "   # axis.gca().add_collection(map_stuff)\n",
    "    axis.add_collection(map_stuff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f7e68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spawns_goals(\n",
    "    drone_radius = 0.5,\n",
    "    goal_tolerance = 4,\n",
    "    goal_distance = 100,\n",
    "    spawns = [],\n",
    "    goals = [],\n",
    "    spawn_color = color_blinds['red'],\n",
    "    goal_color = color_blinds['orange'],\n",
    "    goal_wedge = True,\n",
    "):\n",
    "    # patch stuff\n",
    "    spawn_patches = []\n",
    "    goal_patches = []\n",
    "    for idx in range(len(spawns)):\n",
    "        spawn = spawns[idx]\n",
    "        goal = goals[idx]\n",
    "        spawn_patch = patches.Rectangle(\n",
    "            (spawn[0], spawn[1]), \n",
    "            drone_radius, \n",
    "            drone_radius, \n",
    "            color=spawn_color,\n",
    "        )\n",
    "        spawn_patches.append(spawn_patch)\n",
    "        if goal_wedge:\n",
    "            radius = math.sqrt(goal[0]**2 + goal[1]**2)\n",
    "            goal_patch = patches.Wedge(\n",
    "                (spawn[0], spawn[1]), \n",
    "                goal_distance+goal_tolerance, \n",
    "                goal[0], goal[1], \n",
    "                width=2*goal_tolerance,\n",
    "                color=goal_color,\n",
    "            )\n",
    "        else:\n",
    "            goal_patch = patches.Circle(\n",
    "                (goal[0], goal[1]), \n",
    "                goal_tolerance, \n",
    "                color=goal_color,\n",
    "            )\n",
    "        goal_patches.append(goal_patch)\n",
    "    # add list of patches (much quicker than iteratively drawing)\n",
    "    spawn_collection = PatchCollection(spawn_patches, match_original=True)\n",
    "    goal_collection = PatchCollection(goal_patches, match_original=True)\n",
    "    plt.gca().add_collection(goal_collection)\n",
    "    plt.gca().add_collection(spawn_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a632cd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_environment(name='Learning Environment (to scale)'):\n",
    "    fig = plt.figure()\n",
    "    fig.set_size_inches((6, 6))\n",
    "    plt.title(name)\n",
    "    plt.xlabel('y [meters]')\n",
    "    plt.ylabel('x [meters]')\n",
    "    plt.xlim(-120, 120)\n",
    "    plt.ylim(-120, 120)\n",
    "    # custom legend hack\n",
    "    plt.scatter(-999, -999, marker='s', color=object_color)\n",
    "    plt.scatter(-999, -999, marker='s', color=train_spawn_color)\n",
    "    plt.scatter(-999, -999, color=train_goal_color)\n",
    "    #plt.scatter(-999, -999, color=eval_spawn_color)\n",
    "    #plt.scatter(-999, -999, color=eval_goal_color)\n",
    "    plt.legend([\n",
    "        'Objects', \n",
    "        'Spawn', \n",
    "        'Goal', \n",
    "        #'Eval Spawn', \n",
    "        #'Eval Goal'\n",
    "    ],\n",
    "               loc='center left', \n",
    "               bbox_to_anchor=(1, 0.5),)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4c01db",
   "metadata": {},
   "source": [
    "# EVALUATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32774073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json files output with all string key names\n",
    "# process so that the evaluation dictionary structure is such:\n",
    "    # episode # - int\n",
    "        # step # - int\n",
    "            # state - dictionary of misc key, value pairs for that state\n",
    "def process_episodes(json_evaluation):\n",
    "    nEpisodes = len(json_evaluation)\n",
    "    episodes = [None] * nEpisodes\n",
    "    episode_idx = 0\n",
    "    for episode_str in json_evaluation:\n",
    "        if 'episode_' not in episode_str:\n",
    "            continue\n",
    "        json_episode = json_evaluation[episode_str]\n",
    "        nSteps = len(json_episode)\n",
    "        states = [None] * nSteps\n",
    "        for step_str in json_episode:\n",
    "            step_num = int(step_str.split('_')[1])\n",
    "            state = json_episode[step_str]\n",
    "            states[step_num] = state\n",
    "        episodes[episode_idx] = states\n",
    "        episode_idx += 1\n",
    "    return episodes\n",
    "def read_evaluations(evaluation_folder):\n",
    "    evaluation_files = [file for file in os.listdir(evaluation_folder) if 'states' in file]\n",
    "    nEvaluations = len(evaluation_files)\n",
    "    evaluations = [None] * nEvaluations\n",
    "    for evaluation_file in evaluation_files:\n",
    "        if '.json' not in evaluation_file:\n",
    "            continue\n",
    "        epoch = int(evaluation_file.split('.')[0].split('_')[-1])\n",
    "        print(evaluation_file, epoch)\n",
    "        json_evaluation = json.load(open(evaluation_folder + evaluation_file, 'r'))\n",
    "        episodes = process_episodes(json_evaluation)\n",
    "        evaluations[epoch] = episodes\n",
    "    return evaluations\n",
    "# architecture for evaluations:\n",
    "# evaluations - list of episodes (indexed of evaluation number) - 0 idx is first evaluation\n",
    "    # episodes - list of states (indexed by step number)\n",
    "        # states - dict of (key, value) pairs for state at all_evaluations[instance][evaluation][episode][step]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9c8991",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read evaluations from each instance\n",
    "# each instance is a sub folder from parent with which this eval notebook is in\n",
    "instances = [\n",
    "    'EvaluateEnvironment',\n",
    "    'TrainEnvironment',\n",
    "    ]\n",
    "all_evaluations = {}\n",
    "for instance in instances:\n",
    "    all_evaluations[instance] = read_evaluations(instance + '/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f329e65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read info from config file\n",
    "#config_file = json.load(open('configuration.json', 'r'))\n",
    "gamma = 0.99#config_file['components']['Model']['gamma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051de3b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# process evaluations\n",
    "final_variables = {instance:{} for instance in instances}\n",
    "for instance in instances:\n",
    "    for set_num, episodes in enumerate(all_evaluations[instance]):\n",
    "        for episode, states in enumerate(episodes):\n",
    "            for step, state in enumerate(states):\n",
    "                if step == 0:\n",
    "                    if 'goal_distance' not in final_variables[instance]:\n",
    "                        final_variables[instance]['goal_distance'] = {}\n",
    "                    if episode not in final_variables[instance]['goal_distance']:\n",
    "                        final_variables[instance]['goal_distance'][episode] = []\n",
    "                    drone_position = np.array(state['drone_position'])\n",
    "                    goal_position = np.array(state['goal_position'])\n",
    "                    goal_distance = np.linalg.norm(goal_position - drone_position)\n",
    "                    final_variables[instance]['goal_distance'][episode].append(goal_distance)\n",
    "                    continue\n",
    "            final_state = states[-1]\n",
    "            for variable in final_state:\n",
    "                if variable not in final_variables[instance]:\n",
    "                    final_variables[instance][variable] = {}\n",
    "                if episode not in final_variables[instance][variable]:\n",
    "                    final_variables[instance][variable][episode] = []\n",
    "                final_variables[instance][variable][episode].append(final_state[variable])\n",
    "\n",
    "# architecture of final_variables:\n",
    "# instance - str name\n",
    "    # variable - str name\n",
    "        # episode - int number\n",
    "            # final values - list of final values with increased # of training evaluations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0f8520",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# PLOT RESULTS VERSUS TRAINING TIME\n",
    "results_instances = [\n",
    "    'EvaluateEnvironment', \n",
    "    'TrainEnvironment', \n",
    "]\n",
    "# select which state variables to fetch\n",
    "numerical_variables = [\n",
    "    #'nSteps', \n",
    "    'total_reward', \n",
    "    'goal_distance',\n",
    "]\n",
    "string_variables = [\n",
    "    #'transcribed_action', \n",
    "    'termination_reason',\n",
    "]\n",
    "all_variables = numerical_variables + string_variables\n",
    "\n",
    "shorten = {\n",
    "    'termination_reason':'termination',\n",
    "}\n",
    "\n",
    "# take mean values\n",
    "for variable in all_variables:\n",
    "    for instance in results_instances:\n",
    "        if variable not in shorten:\n",
    "            shorten[variable] = variable\n",
    "        plot_name = instance + '_' + variable\n",
    "        \n",
    "        values = {}\n",
    "        for episode in final_variables[instance][variable]:\n",
    "            for evaluation in range(len(final_variables[instance][variable][episode])):\n",
    "                if evaluation not in values:\n",
    "                    values[evaluation] = []\n",
    "                values[evaluation].append(final_variables[instance][variable][episode][evaluation])\n",
    "\n",
    "        if variable in numerical_variables:\n",
    "            aggregates = []\n",
    "            nEpisodes = len(final_variables[instance][variable])\n",
    "            for evaluation in values:\n",
    "                aggregates.append(sum(values[evaluation])/len(values[evaluation]))\n",
    "            plt.title(instance)\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel(variable)\n",
    "            plt.plot(aggregates)\n",
    "            plt.tight_layout()\n",
    "            fig = plt.gcf()\n",
    "            fig.set_size_inches(8, 4)\n",
    "            plt.savefig(plot_dir + plot_name + '.png')\n",
    "            plt.show()\n",
    "\n",
    "        if variable in string_variables:\n",
    "            fig = plt.gcf()\n",
    "            fig.set_size_inches(4, 4)\n",
    "            aggregates = {}\n",
    "            for evaluation in values:\n",
    "                for name in values[evaluation]:\n",
    "                    if name not in aggregates:\n",
    "                        aggregates[name] = {}\n",
    "                    if evaluation not in aggregates[name]:\n",
    "                        aggregates[name][evaluation] = 0\n",
    "                    aggregates[name][evaluation] += 1   \n",
    "            df_data = {'count':[], shorten[variable]:[], 'epoch':[]}\n",
    "            for name in aggregates:\n",
    "                for evaluation in values:\n",
    "                    if evaluation not in aggregates[name]:\n",
    "                        aggregates[name][evaluation] = 0\n",
    "                    count = aggregates[name][evaluation]\n",
    "                    df_data['count'].append(count)\n",
    "                    df_data[shorten[variable]].append(name[0])\n",
    "                    df_data['epoch'].append(evaluation)\n",
    "            df = pd.DataFrame(df_data)\n",
    "            heatmap_data = pd.pivot_table(df, values='count', index=[shorten[variable]], columns='epoch')\n",
    "            sns.heatmap(heatmap_data, cbar=False)\n",
    "            plt.title(instance)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(plot_dir + plot_name + '.png')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73bcfff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "res = True\n",
    "# PLOT SUCCESS PATHS\n",
    "path_instances = [\n",
    "    'EvaluateEnvironment', \n",
    "    #'TrainEnvironment', \n",
    "]\n",
    "for instance in path_instances:\n",
    "    evaluations = all_evaluations[instance]\n",
    "    for set_num, episodes in enumerate(evaluations):\n",
    "        paths = []\n",
    "        reward_paths = []\n",
    "        rho_paths = []\n",
    "        pf_paths = []\n",
    "        pd_paths = []\n",
    "        Q_paths = []\n",
    "        goals = []\n",
    "        spawns = []\n",
    "        termination_reasons = []\n",
    "        episode_numbers = []\n",
    "        # do we plot this set? (change as needed)\n",
    "        # you can just plot everything but its alot to chew\n",
    "        view_set = True\n",
    "        for episode, states in enumerate(episodes):\n",
    "            # get final vaules\n",
    "            final_state = episodes[episode][-1]\n",
    "            termination_result = final_state['termination_result']\n",
    "            #if 'success' not in termination_result:\n",
    "            #    view_set = False\n",
    "            #    break\n",
    "        if not view_set:\n",
    "            continue\n",
    "        for episode, states in enumerate(episodes):\n",
    "            # get final vaules\n",
    "            final_state = episodes[episode][-1]\n",
    "            termination_reason = final_state['termination_reason']\n",
    "            # build paths\n",
    "            path = []\n",
    "            reward_path = []\n",
    "            rho_path = []\n",
    "            pf_path = []\n",
    "            pd_path = []\n",
    "            Q_path = []\n",
    "            episode_numbers.append(episode)\n",
    "            # get initial value\n",
    "            init_state = states[0]\n",
    "            spawn = init_state['drone_position']\n",
    "            goal = init_state['goal_position']\n",
    "            # get intermediate values\n",
    "            for step, state in enumerate(states):\n",
    "                if step == 0: continue\n",
    "                state = episodes[episode][step]\n",
    "                drone_position = state['drone_position']\n",
    "                path.append(drone_position)\n",
    "                reward = state['total_reward']\n",
    "                reward_path.append(reward)\n",
    "                rho = state['transcribed_action']['slim']\n",
    "                rho_path.append(rho)\n",
    "                pf = state['transcribed_action']['FlattenedDepthResolution']\n",
    "                pf_path.append(pf)\n",
    "                pd = state['transcribed_action']['FlattenedDepthResolution2']\n",
    "                pd_path.append(pd)\n",
    "                # get future values from this state\n",
    "                for step2, state2 in enumerate(states[step+1:]):\n",
    "                    if step == 0: continue\n",
    "                    reward += (gamma**(step2-step)) * state2['total_reward']\n",
    "                Q_path.append(reward)\n",
    "            reward_paths.append(reward_path)\n",
    "            rho_paths.append(rho_path)\n",
    "            pf_paths.append(pf_path)\n",
    "            pd_paths.append(pd_path)\n",
    "            termination_reasons.append(termination_reason)\n",
    "            spawns.append(spawn)\n",
    "            goals.append(goal)\n",
    "            paths.append(path)\n",
    "            Q_paths.append(Q_path)\n",
    "            # plot every 6 episodes \n",
    "            if episode == len(episodes)-1 or (episode > 0 and episode%6 == 0):\n",
    "                print(set_num)\n",
    "                # subplots\n",
    "                fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(nrows=2, ncols=2)\n",
    "                fig.set_size_inches(16, 8)\n",
    "                ax1 = plt.subplot2grid((2, 2), (0, 0), rowspan=2)\n",
    "                ax2 = plt.subplot2grid((2, 2), (0, 1), colspan=1)\n",
    "                ax3 = plt.subplot2grid((2, 2), (1, 1), colspan=1)\n",
    "                # PLOT DRONE PATH\n",
    "                ax1.set_title(f'Drone Path (to scale)')#' Epoch #{set_num}')\n",
    "                ax1.set_xlabel('y [meters]')\n",
    "                ax1.set_ylabel('x [meters]')\n",
    "                ax1.set_xlim(voxels_trans[0], -1*voxels_trans[0])\n",
    "                ax1.set_ylim(voxels_trans[1], -1*voxels_trans[1])\n",
    "                # show objects on map from binvox\n",
    "                plot_map(ax1)\n",
    "                # legend hack\n",
    "                ax1.scatter(-999, -999, marker='s', color=object_color) # off map just for legend\n",
    "                legend = [\n",
    "                #    'Objects'\n",
    "                ]\n",
    "                for idx in range(len(termination_reasons)):\n",
    "                    color = color_blinds_list[idx]\n",
    "                    radius = 64 * spawns[idx][2]/-4\n",
    "                    #ax1.scatter(spawns[idx][1], spawns[idx][0], marker='x', color=color) # spawn location\n",
    "                    ax1.scatter(spawns[idx][1], spawns[idx][0], s=radius, color=color, marker = unique_markers[idx])\n",
    "                    termination_reason = termination_reasons[idx]\n",
    "                    legend.append('E' + str(episode_numbers[idx]) + ':' + termination_reason)\n",
    "                plt_patches = []\n",
    "                for idx in range(len(paths)):\n",
    "                    color = color_blinds_list[idx]\n",
    "                    # plot goal\n",
    "                    obj = plt.Circle((goals[idx][1], goals[idx][0]), 4, color=color, alpha=0.4)\n",
    "                    plt_patches.append(obj)\n",
    "                    # plot points\n",
    "                    for point in paths[idx]:\n",
    "                        # using generic quad copter size for point sizes (set this to your drone value)\n",
    "                        radius = 64 * point[2]/-4\n",
    "                        ax1.scatter(point[1], point[0], s=radius, color=color, marker = unique_markers[idx])\n",
    "                        #point = plt.Circle((point[1], point[0]), radius, color=color)\n",
    "                        #plt_patches.append(point)\n",
    "                    # plot end point\n",
    "                    #ax1.scatter(paths[idx][-1][1], paths[idx][-1][0], marker='*', s=64, color=color) # end location\n",
    "                map_stuff = PatchCollection(plt_patches, match_original=True)\n",
    "                ax1.add_collection(map_stuff)\n",
    "                plt.tight_layout()\n",
    "                # PLOT REWARDS\n",
    "                if not res:\n",
    "                    ax2.set_title('Slimmable Factor Path')\n",
    "                    ax2.set_ylabel(r'$rho$')\n",
    "                    for idx in range(len(rho_paths)):\n",
    "                        ax2.scatter([i+1.1+.1*idx for i in range(len(rho_paths[idx]))], rho_paths[idx]\n",
    "                                    , color=color_blinds_list[idx], marker=unique_markers[idx], s=64)\n",
    "                    ax2.set_ylim([-.1, 1.1])\n",
    "                else:\n",
    "                    ax2.set_title('Forward Facing Sensor')\n",
    "                    ax2.set_ylabel(r'$p_f$')\n",
    "                    for idx in range(len(pf_paths)):\n",
    "                        ax2.scatter([i+1.1+.1*idx for i in range(len(pf_paths[idx]))], pf_paths[idx]\n",
    "                                    , color=color_blinds_list[idx], marker=unique_markers[idx], s=64)\n",
    "                    ax2.set_ylim([-.1, 3.1])\n",
    "                max_step = 0\n",
    "                for idx in range(len(rho_paths)):\n",
    "                    max_step = max(max_step, len(rho_paths[idx]))\n",
    "                xticks = [i+1.5 for i in range(max_step)]\n",
    "                labels = [str(i+1) for i in range(max_step)]\n",
    "                #ax2.set_xticks(xticks)\n",
    "                #ax2.grid(axis='x')\n",
    "                for i in range(max_step):\n",
    "                    ax2.axvline(x = i+1, color = 'gray', ls=':')\n",
    "                ax2.set_xticks(xticks, labels, rotation = 45)\n",
    "                ax2.set_xlim(1, max_step+1)\n",
    "                #ax2.set_xticklabels(ax2.get_xticks(), rotation = 45)\n",
    "                '''\n",
    "                ax2.set_title('Reward Path')\n",
    "                #ax2.set_xlabel('Step')\n",
    "                ax2.set_ylabel('Immediate Reward')\n",
    "                for idx in range(len(reward_paths)):\n",
    "                    color = color_blinds_list[idx]\n",
    "                    ax2.plot([i+1 for i in range(len(reward_paths[idx]))], reward_paths[idx], color=color, marker='.')\n",
    "                '''\n",
    "                # PLOT Q-VALUES\n",
    "                ax3.set_xlabel('Step')\n",
    "                if not res:\n",
    "                    ax3.set_title('Q-value Path')\n",
    "                    ax3.set_ylabel('Accumlated Reward')\n",
    "                    for idx in range(len(Q_paths)):\n",
    "                        ax3.scatter([i+1.1+.1*idx for i in range(len(Q_paths[idx]))], Q_paths[idx]\n",
    "                                    , color=color_blinds_list[idx], marker=unique_markers[idx], s=64)\n",
    "                else:\n",
    "                    ax3.set_title('Downward Facing Sensor')\n",
    "                    ax3.set_ylabel(r'$p_d$')\n",
    "                    for idx in range(len(pd_paths)):\n",
    "                        ax3.scatter([i+1.1+.1*idx for i in range(len(pd_paths[idx]))], pd_paths[idx]\n",
    "                                    , color=color_blinds_list[idx], marker=unique_markers[idx], s=64)\n",
    "                    ax3.set_ylim([-.1, 3.1])\n",
    "                ax3.set_xticks(xticks, labels, rotation = 45)\n",
    "                for i in range(max_step):\n",
    "                    ax3.axvline(x = i+1, color = 'gray', ls=':')\n",
    "                ax3.set_xticks(xticks, labels, rotation = 45)\n",
    "                ax3.set_xlim(1, max_step+1)\n",
    "                # plot legend\n",
    "                #ax1.legend(legend, loc='lower left', bbox_to_anchor=(0., 0.), fancybox=True, shadow=True, ncol=6)\n",
    "                # Show the graph\n",
    "                plot_name = instance + '_best_path'\n",
    "                plt.savefig(plot_dir + plot_name + '.png')\n",
    "                plt.show()\n",
    "                # reset path arrays\n",
    "                paths = []\n",
    "                reward_paths = []\n",
    "                Q_paths = []\n",
    "                goals = []\n",
    "                spawns = []\n",
    "                termination_reasons = []\n",
    "                episode_numbers = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253df546",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# PLOT SUCCESS PATHS\n",
    "path_instances = [\n",
    "    'EvaluateEnvironment', \n",
    "    #'TrainEnvironment', \n",
    "]\n",
    "for instance in path_instances:\n",
    "    evaluations = all_evaluations[instance]\n",
    "    for set_num, episodes in enumerate(evaluations):\n",
    "        paths = []\n",
    "        reward_paths = []\n",
    "        rho_paths = []\n",
    "        pf_paths = []\n",
    "        pd_paths = []\n",
    "        Q_paths = []\n",
    "        goals = []\n",
    "        spawns = []\n",
    "        termination_reasons = []\n",
    "        episode_numbers = []\n",
    "        # do we plot this set? (change as needed)\n",
    "        # you can just plot everything but its alot to chew\n",
    "        view_set = True\n",
    "        for episode, states in enumerate(episodes):\n",
    "            # get final vaules\n",
    "            final_state = episodes[episode][-1]\n",
    "            termination_result = final_state['termination_result']\n",
    "            #if 'success' not in termination_result:\n",
    "            #    view_set = False\n",
    "            #    break\n",
    "        if not view_set:\n",
    "            continue\n",
    "        for episode, states in enumerate(episodes):\n",
    "            # get final vaules\n",
    "            final_state = episodes[episode][-1]\n",
    "            termination_reason = final_state['termination_reason']\n",
    "            # build paths\n",
    "            path = []\n",
    "            reward_path = []\n",
    "            rho_path = []\n",
    "            pf_path = []\n",
    "            pd_path = []\n",
    "            Q_path = []\n",
    "            episode_numbers.append(episode)\n",
    "            # get initial value\n",
    "            init_state = states[0]\n",
    "            spawn = init_state['drone_position']\n",
    "            goal = init_state['goal_position']\n",
    "            # get intermediate values\n",
    "            for step, state in enumerate(states):\n",
    "                if step == 0: continue\n",
    "                state = episodes[episode][step]\n",
    "                drone_position = state['drone_position']\n",
    "                path.append(drone_position)\n",
    "                reward = state['total_reward']\n",
    "                reward_path.append(reward)\n",
    "                rho = state['transcribed_action']['slim']\n",
    "                rho_path.append(rho)\n",
    "                pf = state['transcribed_action']['FlattenedDepthResolution']\n",
    "                pf_path.append(pf)\n",
    "                pd = state['transcribed_action']['FlattenedDepthResolution2']\n",
    "                pd_path.append(pd)\n",
    "                # get future values from this state\n",
    "                for step2, state2 in enumerate(states[step+1:]):\n",
    "                    if step == 0: continue\n",
    "                    reward += (gamma**(step2-step)) * state2['total_reward']\n",
    "                Q_path.append(reward)\n",
    "            reward_paths.append(reward_path)\n",
    "            rho_paths.append(rho_path)\n",
    "            pf_paths.append(pf_path)\n",
    "            pd_paths.append(pd_path)\n",
    "            termination_reasons.append(termination_reason)\n",
    "            spawns.append(spawn)\n",
    "            goals.append(goal)\n",
    "            paths.append(path)\n",
    "            Q_paths.append(Q_path)\n",
    "            # plot every 6 episodes \n",
    "            if episode == len(episodes)-1 or (episode > 0 and episode%6 == 0):\n",
    "                print(set_num)\n",
    "                # subplots\n",
    "                fig, axs = plt.subplots(nrows=3, ncols=2)\n",
    "                fig.set_size_inches(16, 12)\n",
    "                ax1 = plt.subplot2grid((3, 2), (0, 0), rowspan=2)\n",
    "                ax2 = plt.subplot2grid((3, 2), (0, 1), colspan=1)\n",
    "                ax3 = plt.subplot2grid((3, 2), (1, 1), colspan=1)\n",
    "                ax4 = plt.subplot2grid((3, 2), (2, 1), colspan=1)\n",
    "                ax5 = plt.subplot2grid((3, 2), (2, 0), colspan=1)\n",
    "                # PLOT DRONE PATH\n",
    "                ax1.set_title(f'Drone Path (to scale)')#' Epoch #{set_num}')\n",
    "                ax1.set_xlabel('y [meters]')\n",
    "                ax1.set_ylabel('x [meters]')\n",
    "                ax1.set_xlim(voxels_trans[0], -1*voxels_trans[0])\n",
    "                ax1.set_ylim(voxels_trans[1], -1*voxels_trans[1])\n",
    "                # show objects on map from binvox\n",
    "                plot_map(ax1)\n",
    "                # legend hack\n",
    "                ax1.scatter(-999, -999, marker='s', color=object_color) # off map just for legend\n",
    "                legend = [\n",
    "                #    'Objects'\n",
    "                ]\n",
    "                for idx in range(len(termination_reasons)):\n",
    "                    color = color_blinds_list[idx]\n",
    "                    radius = 64 * spawns[idx][2]/-4\n",
    "                    #ax1.scatter(spawns[idx][1], spawns[idx][0], marker='x', color=color) # spawn location\n",
    "                    ax1.scatter(spawns[idx][1], spawns[idx][0], s=radius, color=color, marker = unique_markers[idx])\n",
    "                    termination_reason = termination_reasons[idx]\n",
    "                    legend.append('E' + str(episode_numbers[idx]) + ':' + termination_reason)\n",
    "                plt_patches = []\n",
    "                for idx in range(len(paths)):\n",
    "                    color = color_blinds_list[idx]\n",
    "                    # plot goal\n",
    "                    obj = plt.Circle((goals[idx][1], goals[idx][0]), 4, color=color, alpha=0.4)\n",
    "                    plt_patches.append(obj)\n",
    "                    # plot points\n",
    "                    for point in paths[idx]:\n",
    "                        # using generic quad copter size for point sizes (set this to your drone value)\n",
    "                        radius = 64 * point[2]/-4\n",
    "                        ax1.scatter(point[1], point[0], s=radius, color=color, marker = unique_markers[idx])\n",
    "                        #point = plt.Circle((point[1], point[0]), radius, color=color)\n",
    "                        #plt_patches.append(point)\n",
    "                    # plot end point\n",
    "                    #ax1.scatter(paths[idx][-1][1], paths[idx][-1][0], marker='*', s=64, color=color) # end location\n",
    "                map_stuff = PatchCollection(plt_patches, match_original=True)\n",
    "                ax1.add_collection(map_stuff)\n",
    "                # max steps and ticks\n",
    "                plt.tight_layout()\n",
    "                max_step = 0\n",
    "                for idx in range(len(rho_paths)):\n",
    "                    max_step = max(max_step, len(rho_paths[idx]))\n",
    "                xticks = [i+1.5 for i in range(max_step)]\n",
    "                labels = [str(i+1) for i in range(max_step)]\n",
    "                # Slimmable Factor Path\n",
    "                ax2.set_title('Slimmable Factor Path')\n",
    "                ax2.set_ylabel(r'$rho$')\n",
    "                for idx in range(len(rho_paths)):\n",
    "                    ax2.scatter([i+1.1+.1*idx for i in range(len(rho_paths[idx]))], rho_paths[idx]\n",
    "                                , color=color_blinds_list[idx], marker=unique_markers[idx], s=64)\n",
    "                ax2.set_ylim([-.1, 1.1])\n",
    "                # Forward Facing Sensor\n",
    "                ax3.set_title('Forward Facing Sensor')\n",
    "                ax3.set_ylabel(r'$p_f$')\n",
    "                for idx in range(len(pf_paths)):\n",
    "                    ax3.scatter([i+1.1+.1*idx for i in range(len(pf_paths[idx]))], pf_paths[idx]\n",
    "                                , color=color_blinds_list[idx], marker=unique_markers[idx], s=64)\n",
    "                ax3.set_ylim([-.1, 3.1])\n",
    "                # Downward Facing Sensor\n",
    "                ax4.set_xlabel('Step')\n",
    "                ax4.set_title('Downward Facing Sensor')\n",
    "                ax4.set_ylabel(r'$p_d$')\n",
    "                for idx in range(len(pd_paths)):\n",
    "                    ax4.scatter([i+1.1+.1*idx for i in range(len(pd_paths[idx]))], pd_paths[idx]\n",
    "                                , color=color_blinds_list[idx], marker=unique_markers[idx], s=64)\n",
    "                ax4.set_ylim([-.1, 3.1])\n",
    "                # Q-value Path\n",
    "                ax5.set_xlabel('Step')\n",
    "                ax5.set_title('Q-value Path')\n",
    "                ax5.set_ylabel('Accumlated Reward')\n",
    "                for idx in range(len(Q_paths)):\n",
    "                    ax5.scatter([i+1.1+.1*idx for i in range(len(Q_paths[idx]))], Q_paths[idx]\n",
    "                                , color=color_blinds_list[idx], marker=unique_markers[idx], s=64)\n",
    "                # vert lines\n",
    "                for i in range(max_step):\n",
    "                    ax2.axvline(x = i+1, color = 'gray', ls=':')\n",
    "                ax2.set_xticks(xticks, labels, rotation = 45)\n",
    "                ax2.set_xlim(1, max_step+1)\n",
    "                for i in range(max_step):\n",
    "                    ax3.axvline(x = i+1, color = 'gray', ls=':')\n",
    "                ax3.set_xticks(xticks, labels, rotation = 45)\n",
    "                ax3.set_xlim(1, max_step+1)\n",
    "                for i in range(max_step):\n",
    "                    ax4.axvline(x = i+1, color = 'gray', ls=':')\n",
    "                ax4.set_xticks(xticks, labels, rotation = 45)\n",
    "                ax4.set_xlim(1, max_step+1)\n",
    "                for i in range(max_step):\n",
    "                    ax5.axvline(x = i+1, color = 'gray', ls=':')\n",
    "                ax5.set_xticks(xticks, labels, rotation = 45)\n",
    "                ax5.set_xlim(1, max_step+1)\n",
    "               \n",
    "            \n",
    "                # Show the graph\n",
    "                plot_name = instance + '_best_path'\n",
    "                plt.savefig(plot_dir + plot_name + '.png')\n",
    "                plt.show()\n",
    "                # reset path arrays\n",
    "                paths = []\n",
    "                reward_paths = []\n",
    "                Q_paths = []\n",
    "                goals = []\n",
    "                spawns = []\n",
    "                termination_reasons = []\n",
    "                episode_numbers = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6d9221",
   "metadata": {},
   "source": [
    "# SUMMARY FIGURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f706b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = np.asarray(Image.open(plot_dir + 'EvaluateEnvironment_goal_distance.png'))\n",
    "img2 = np.asarray(Image.open(plot_dir + 'EvaluateEnvironment_best_path.png'))\n",
    "img3 = np.asarray(Image.open(plot_dir + 'EvaluateEnvironment_termination_reason.png'))\n",
    "img4 = np.asarray(Image.open(plot_dir + 'TrainEnvironment_termination_reason.png'))\n",
    "\n",
    "gshape = [img2.shape[0], img1.shape[1] + img2.shape[1], 4]\n",
    "gimg = np.zeros(gshape, dtype=np.uint8)\n",
    "gimg[:img1.shape[0],:img1.shape[1],:] = img1\n",
    "gimg[:,img1.shape[1]:,:] = img2\n",
    "gimg[img1.shape[0]:,:img3.shape[1],:] = img3\n",
    "gimg[img1.shape[0]:,img3.shape[1]:img1.shape[1],:] = img4\n",
    "\n",
    "plt.imshow(gimg)\n",
    "plt.axis('off')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(24, 8)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611c75ee",
   "metadata": {},
   "source": [
    "# SUPPLEMENTAL SCRIPTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905bef58",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# process evaluations\n",
    "instance = 'EvaluateEnvironment'\n",
    "#set_num = 260\n",
    "mean_levels = []\n",
    "for set_num, episodes in enumerate(all_evaluations[instance]):\n",
    "    if set_num > 142:\n",
    "        break\n",
    "    episodes = all_evaluations[instance][set_num]\n",
    "    resolution_levels = []\n",
    "    for episode, states in enumerate(episodes):\n",
    "        for step, state in enumerate(states):\n",
    "            if step == 0:\n",
    "                drone_position = np.array(state['drone_position'])\n",
    "                goal_position = np.array(state['goal_position'])\n",
    "                goal_distance = np.linalg.norm(goal_position - drone_position)\n",
    "                continue\n",
    "            else:\n",
    "                resolution_level = int(4*state['rl_output'][0])\n",
    "                resolution_levels.append(resolution_level)\n",
    "    mean_level = np.mean(resolution_levels)\n",
    "    mean_levels.append(mean_level)\n",
    "plt.plot(mean_levels)\n",
    "plt.title('Blocks Environment')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean Resolution Level')\n",
    "plt.show()\n",
    "# architecture of final_variables:\n",
    "# instance - str name\n",
    "    # variable - str name\n",
    "        # episode - int number\n",
    "            # final values - list of final values with increased # of training evaluations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013c448e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIEW ALL PATHS (THIS CAN BE ALOT)\n",
    "# # plot final paths (run necessary binvox stuff at bottom of notebook to use plot_map)\n",
    "for instance in instances:\n",
    "    evaluations = all_evaluations[instance]\n",
    "    if 'train' in instance:\n",
    "        evaluations = [evaluations[-1]]\n",
    "    for set_num, episodes in enumerate(evaluations):\n",
    "        if set_num > 100:\n",
    "            continue\n",
    "        paths = []\n",
    "        reward_paths = []\n",
    "        Q_paths = []\n",
    "        goals = []\n",
    "        spawns = []\n",
    "        termination_reasons = []\n",
    "        episode_numbers = []\n",
    "        for episode, states in enumerate(episodes):\n",
    "            path = []\n",
    "            reward_path = []\n",
    "            Q_path = []\n",
    "            episode_numbers.append(episode)\n",
    "            # get initial value\n",
    "            init_state = states[0]\n",
    "            spawn = init_state['drone_position']\n",
    "            spawns.append(spawn)\n",
    "            goal = init_state['goal_position']\n",
    "            goals.append(goal)\n",
    "            # get intermediate values\n",
    "            for step, state in enumerate(states):\n",
    "                if step == 0: continue\n",
    "                state = episodes[episode][step]\n",
    "                drone_position = state['drone_position']\n",
    "                path.append(drone_position)\n",
    "                reward = state['total_reward']\n",
    "                reward_path.append(reward)\n",
    "                # get future values from this state\n",
    "                for step2, state2 in enumerate(states[step+1:]):\n",
    "                    if step == 0: continue\n",
    "                    reward += (gamma**(step2-step)) * state2['total_reward']\n",
    "                Q_path.append(reward)\n",
    "            paths.append(path)\n",
    "            reward_paths.append(reward_path)\n",
    "            Q_paths.append(Q_path)\n",
    "            # get final vaules\n",
    "            final_state = episodes[episode][-1]\n",
    "            termination_reason = final_state['termination_reason']\n",
    "            termination_reasons.append(termination_reason)\n",
    "            # plot every 8 episodes \n",
    "            if episode == len(episodes)-1 or (episode > 0 and episode%8 == 0):\n",
    "                # subplots\n",
    "                fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(nrows=2, ncols=2)\n",
    "                if 'train' in instance:\n",
    "                    fig.suptitle(instance + ' Final Set')\n",
    "                else:\n",
    "                    fig.suptitle(instance + ' Set #' + str(set_num))\n",
    "                fig.set_figheight(8)\n",
    "                fig.set_figwidth(16)\n",
    "                ax1 = plt.subplot2grid((2, 2), (0, 0), rowspan=2)\n",
    "                ax2 = plt.subplot2grid((2, 2), (0, 1), colspan=1)\n",
    "                ax3 = plt.subplot2grid((2, 2), (1, 1), colspan=1)\n",
    "                # PLOT DRONE PATH\n",
    "                ax1.set_title('Drone Path (to scale)')\n",
    "                ax1.set_xlabel('y [meters]')\n",
    "                ax1.set_ylabel('x [meters]')\n",
    "                ax1.set_xlim(-100, 100)\n",
    "                ax1.set_ylim(-100, 100)\n",
    "                # show objects on map from binvox\n",
    "                plot_map(ax1)\n",
    "                # legend hack\n",
    "                ax1.scatter(-999, -999, marker='s', color=object_color) # off map just for legend\n",
    "                legend = [\n",
    "                #    'Objects'\n",
    "                ]\n",
    "                for idx in range(len(termination_reasons)):\n",
    "                    color = color_blinds_list[idx]\n",
    "                    ax1.scatter(spawns[idx][1], spawns[idx][0], marker='x', color=color) # spawn location\n",
    "                    termination_reason = termination_reasons[idx]\n",
    "                    legend.append('E' + str(episode_numbers[idx]) + ':' + termination_reason)\n",
    "                plt_patches = []\n",
    "                for idx in range(len(paths)):\n",
    "                    color = color_blinds_list[idx]\n",
    "                    # plot goal\n",
    "                    obj = plt.Circle((goals[idx][1], goals[idx][0]), 4, color=color, alpha=0.4)\n",
    "                    plt_patches.append(obj)\n",
    "                    # plot points\n",
    "                    for point in paths[idx]:\n",
    "                        # using generic quad copter size for point sizes (set this to your drone value)\n",
    "                        radius = 0.5\n",
    "                        point = plt.Circle((point[1], point[0]), radius, color=color)\n",
    "                        plt_patches.append(point)\n",
    "                    # plot end point\n",
    "                    ax1.scatter(paths[idx][-1][1], paths[idx][-1][0], marker='*', s=64, color=color) # end location\n",
    "                map_stuff = PatchCollection(plt_patches, match_original=True)\n",
    "                ax1.add_collection(map_stuff)\n",
    "                # PLOT REWARDS\n",
    "                ax2.set_title('Reward Path')\n",
    "                #ax2.set_xlabel('Step')\n",
    "                ax2.set_ylabel('Immediate Reward')\n",
    "                for idx in range(len(reward_paths)):\n",
    "                    color = color_blinds_list[idx]\n",
    "                    ax2.plot([i+1 for i in range(len(reward_paths[idx]))], reward_paths[idx], color=color, marker='.')\n",
    "                # PLOT Q-VALUES\n",
    "                ax3.set_title('Q-value Path')\n",
    "                ax3.set_xlabel('Step')\n",
    "                ax3.set_ylabel('Accumlated Reward')\n",
    "                for idx in range(len(Q_paths)):\n",
    "                    color = color_blinds_list[idx]\n",
    "                    ax3.plot([i+1 for i in range(len(Q_paths[idx]))], Q_paths[idx], color=color, marker='.')\n",
    "                # plot legend\n",
    "                ax2.legend(legend, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "                # Show the graph\n",
    "                plt.show()\n",
    "                # reset path arrays\n",
    "                paths = []\n",
    "                reward_paths = []\n",
    "                Q_paths = []\n",
    "                goals = []\n",
    "                spawns = []\n",
    "                termination_reasons = []\n",
    "                episode_numbers = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf29e675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOVE HISTORY\n",
    "# view moves for each evaluation for each episode\n",
    "# also keeps track of an AirSim bug that places drone below floor\n",
    "bugs = []\n",
    "read_instances =[\n",
    "    'EvaluateEnvironment', \n",
    "    #'TrainEnvironment', \n",
    "]\n",
    "for instance in read_instances:\n",
    "    evaluations = all_evaluations[instance]\n",
    "    for set_num, episodes in enumerate(evaluations):\n",
    "        for episode, states in enumerate(episodes):\n",
    "            for step, state in enumerate(states):\n",
    "                if state['drone_position'][2] > 0:\n",
    "                    bugs.append((instance, set_num, episode, state['drone_position']))\n",
    "            if 'train' not in instance or set_num == len(evaluations)-1:\n",
    "                if 'train' in instance:\n",
    "                    print('Instance', instance, 'Final Set', 'Epsode', episode)\n",
    "                else:\n",
    "                    print('Instance', instance, 'Set#', set_num, 'Epsode', episode)\n",
    "                for step, state in enumerate(states):\n",
    "                    if step == 0: continue\n",
    "                    action = state['rl_output']\n",
    "                    marker = np.round(action,2)\n",
    "                    if 'Right' in action:\n",
    "                        marker = 'R'\n",
    "                    if 'Left' in action:\n",
    "                        marker = 'L'\n",
    "                    if 'Forward' in action:\n",
    "                        marker = 'F'\n",
    "                    if 'Up' in action:\n",
    "                        marker = 'U'\n",
    "                    if 'Down' in action:\n",
    "                        marker = 'D'\n",
    "                    print(marker, end=' ')\n",
    "                termination_reason = states[-1]['termination_reason']\n",
    "                print(termination_reason)\n",
    "bugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bef593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view specific observations\n",
    "\n",
    "# read observations\n",
    "directory = 'TrainEnvironment/'\n",
    "files = [file for file in os.listdir(directory) if 'observations' in file]\n",
    "observations = {}\n",
    "for file in files:\n",
    "    observation_set = np.load(directory + file, allow_pickle=True)\n",
    "    observations.update(observation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b747abbb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# process evaluations\n",
    "instance = 'TrainEnvironment'\n",
    "max_res = 4\n",
    "last_rl0 = max_res\n",
    "last_rl1 = max_res\n",
    "for set_num, episodes in enumerate(all_evaluations[instance]):\n",
    "    for episode, states in enumerate(episodes):\n",
    "        for step, state in enumerate(states):\n",
    "            if step == 0:\n",
    "                last_rl0 = max_res\n",
    "                last_rl1 = max_res\n",
    "                l0 = 's'\n",
    "                l1 = 's'\n",
    "            if step > 0:\n",
    "                obs_name = state['observation_name']\n",
    "                obs = observations[obs_name]\n",
    "                print(len(obs))\n",
    "                np.set_printoptions(precision=2)\n",
    "                print(f'STEP:{step}')\n",
    "                print(f'Forward Facing Depths, res level = {last_rl0} {l0}')\n",
    "                print(obs[6:87].reshape(9,9))\n",
    "                print(f'Forward Facing Depths, res level = {last_rl1} {l1}')\n",
    "                print(obs[87:87+81].reshape(9,9))\n",
    "                print()\n",
    "                last_rl0 = int((max_res+1)*state['rl_output'][0])\n",
    "                l0 = state['rl_output'][0]\n",
    "                last_rl1 = int((max_res+1)*state['rl_output'][1])\n",
    "                l1 = state['rl_output'][1]\n",
    "        x = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5914b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_name = 'V165061_V165062_V165063_V165065_V165066_V165055_V165056_V165057_V165059_V165060_V165049_V165050_V165051_V165053_V165054'\n",
    "obs = observations[obs_name]\n",
    "nTimesteps = 4\n",
    "vLength = int(len(obs) / nTimesteps)\n",
    "for n in range(nTimesteps):\n",
    "    print(f'At timestep {n}:')\n",
    "    print(obs[vLength*n:vLength*n+vLength])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a759dd6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SLIDESHOW\n",
    "import cv2\n",
    "# use this code to make a slideshow from given observations\n",
    "# will require some small editing for your needs\n",
    "# will plot various time steps along with rewards + actions taken\n",
    "vec_names = ['DG', 'YG', 'AG']\n",
    "for i in range(5):\n",
    "    vec_names.append('D' + str(i))\n",
    "nVec = len(vec_names)\n",
    "nTimesteps = 4\n",
    "vecPad = 10\n",
    "for instance in instances:\n",
    "    print(instance)\n",
    "    directory = instance_paths[instance]\n",
    "    slideshow_path = directory + 'slideshow/'\n",
    "    if not os.path.exists(slideshow_path):\n",
    "        os.mkdir(slideshow_path)\n",
    "    # read observations\n",
    "    files = [file for file in os.listdir(directory) if 'observations' in file]\n",
    "    observations = {}\n",
    "    for file in files:\n",
    "        observation_set = np.load(directory + file, allow_pickle=True)\n",
    "        observations.update(observation_set)\n",
    "    # plot slides and save as png files\n",
    "    slides = []\n",
    "    evaluations = [all_evaluations[instance][-1]]\n",
    "    for evaluation, episodes in enumerate(evaluations):\n",
    "        if 'train' in instance:\n",
    "            episodes = episodes[0:10]\n",
    "        for episode, states in enumerate(episodes):\n",
    "            for step, state in enumerate(states):\n",
    "                if step == 0:\n",
    "                    continue\n",
    "                # get state values\n",
    "                transcribed_action = state['transcribed_action']\n",
    "                done = state['done']\n",
    "                if done:\n",
    "                    termination_reason = state['termination_reason']\n",
    "                observation_key = state['observation_component']\n",
    "                # get observation and params\n",
    "                if observation_key not in observations:\n",
    "                    continue\n",
    "                observation = observations[observation_key]\n",
    "                # check if observation is multi, vec, or img\n",
    "                if len(observation.shape) == 0:\n",
    "                    obs_type = 'multi'\n",
    "                    img_array = observation.item()['img']\n",
    "                    vec_array = observation.item()['vec']\n",
    "                elif len(observation.shape) == 1:\n",
    "                    obs_type = 'vec'\n",
    "                    nRows = 1\n",
    "                    nCols = 84\n",
    "                    empty_array = np.zeros((nRows, nCols*nTimesteps + nTimesteps - 1), dtype=np.int16)\n",
    "                    vec_array = observation\n",
    "                else:\n",
    "                    obs_type = 'img'\n",
    "                    img_array = observation\n",
    "                # show image array\n",
    "                if obs_type in ['multi', 'img']:\n",
    "                    nBands = img_array.shape[0]\n",
    "                    nRows = img_array.shape[1]\n",
    "                    nCols = img_array.shape[2]\n",
    "                    view_shape = (nRows, nBands * nCols + nBands - 1)\n",
    "                    # view side by side\n",
    "                    side_by_side = np.zeros(view_shape, dtype=np.int16)\n",
    "                    side_by_side\n",
    "                    for band in range(nBands):\n",
    "                        side_by_side[0:nRows, (band*nCols+band):(band*nCols+band)+nCols] = img_array[band]\n",
    "                    plt.plot([0, view_shape[1]], [21, 21], color='green')\n",
    "                    plt.plot([0, view_shape[1]], [42, 42], color='green')\n",
    "                    plt.plot([0, view_shape[1]], [63, 63], color='green')\n",
    "                    \n",
    "                    for i in range(nBands):\n",
    "                        plt.plot([16 + i*nCols+i, 16 + i*nCols+i], [0, 84], color='green')\n",
    "                        plt.plot([32 + i*nCols+i, 32 + i*nCols+i], [0, 84], color='green')\n",
    "                        plt.plot([52 + i*nCols+i, 52 + i*nCols+i], [0, 84], color='green')\n",
    "                        plt.plot([68 + i*nCols+i, 68 + i*nCols+i], [0, 84], color='green')\n",
    "                    plt.imshow(side_by_side, cmap='gray')\n",
    "                # show vector array\n",
    "                if obs_type in ['multi', 'vec']:\n",
    "                    if obs_type == 'vec':\n",
    "                        plt.imshow(empty_array, cmap='gray')\n",
    "                    x = 0\n",
    "                    for time in range(nTimesteps):\n",
    "                        y = nRows + vecPad\n",
    "                        for i, name in enumerate(vec_names):\n",
    "                            value = vec_array[time*nVec + i]\n",
    "                            plt.text(x, y, name + ':' + str(round(value, 2)))\n",
    "                            y += vecPad\n",
    "                        x += nCols + 1\n",
    "                plt.axis('off')\n",
    "                title = 'Eps ' + str(episode) + '  Step ' + str(step) + '  Act ' + transcribed_action\n",
    "                title += '' if not done else '  Term ' + termination_reason\n",
    "                plt.title(title)\n",
    "                #slide_name = title + '.png'\n",
    "                #plt.savefig(slideshow_path + slide_name)\n",
    "                #slides.append(slide_name)\n",
    "                plt.show()      \n",
    "                \n",
    "    # make video from frames\n",
    "    frames = []\n",
    "    for slide_name in slides:\n",
    "        frame_path = slideshow_path + slide_name\n",
    "        frame = cv2.imread(frame_path)\n",
    "        frame_shape = frame.shape\n",
    "        frames.append(frame)\n",
    "    video_path = slideshow_path + instance + '_slideshow.avi'\n",
    "    video = cv2.VideoWriter(\n",
    "                            filename = video_path, \n",
    "                            fourcc = 0,\n",
    "                            fps = 1,\n",
    "                            frameSize = (frame_shape[1], frame_shape[0]),\n",
    "                            isColor = True,\n",
    "                           )\n",
    "    for frame in frames:\n",
    "        video.write(frame)\n",
    "    video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbca36b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# play with reward function\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "def distance(d):\n",
    "    #return -1*np.exp(-1*d)\n",
    "    #return 1*(np.tanh(d) - 1)\n",
    "    return .1*d\n",
    "def steps(s):\n",
    "    return -1\n",
    "def resolution(c1, c2):\n",
    "    return -2*c1#1*(np.exp(-*c1)-1) #+ np.exp(-.5*c2)-1 # two sensors to detect resolution\n",
    "def goal(yes):\n",
    "    return 100 if yes else 0\n",
    "def collision(yes):\n",
    "    return -100 if yes else 0\n",
    "\n",
    "gamma = 0.99\n",
    "start_distance = 100\n",
    "qsc = []\n",
    "qsS2 = []\n",
    "qsS = []\n",
    "qs = []\n",
    "qs0 = []\n",
    "qs1 = []\n",
    "qs2 = []\n",
    "qs3 = []\n",
    "qs4 = []\n",
    "steps_to_goal = []\n",
    "max_steps = 1000\n",
    "mean_steps = np.arange(1, 10, .1)\n",
    "for mean_step in mean_steps:\n",
    "    d = start_distance\n",
    "    c = c1 = c2 = 4\n",
    "    s = 0\n",
    "    r = distance(d) + steps(s) + resolution(c1,c2) + goal(False) + collision(False)\n",
    "    rc = distance(d) + steps(s+1) + resolution(c1,c2) + goal(False) + collision(True)\n",
    "    qc = r+gamma*rc\n",
    "    qsc.append(qc)\n",
    "    q = q0 = q1 = q2 = q3 = q4 = qS = qS2 = r\n",
    "    not_added = True\n",
    "    while(True):\n",
    "        s += 1\n",
    "        #step = mean_step\n",
    "        step = np.random.normal(mean_step, mean_step)\n",
    "        d = d-step\n",
    "        reached = d < 4\n",
    "        r = distance(0) + steps(s) + resolution(0,0) + goal(False) + collision(False)\n",
    "        r0 = distance(step) + steps(s) + resolution(0,0) + goal(reached) + collision(False)\n",
    "        r1 = distance(step) + steps(s) + resolution(1,1) + goal(reached) + collision(False)\n",
    "        r2 = distance(step) + steps(s) + resolution(2,2) + goal(reached) + collision(False)\n",
    "        r3 = distance(step) + steps(s) + resolution(3,3) + goal(reached) + collision(False)\n",
    "        r4 = distance(step) + steps(s) + resolution(4,4) + goal(reached) + collision(False)\n",
    "        rS2 = distance(step) + steps(s) + resolution(0,0) + goal(False) + collision(False)\n",
    "        q += r * gamma**s\n",
    "        q0 += r0 * gamma**s\n",
    "        q1 += r1 * gamma**s\n",
    "        q2 += r2 * gamma**s\n",
    "        q3 += r3 * gamma**s\n",
    "        q4 += r4 * gamma**s\n",
    "        qS2 += rS2 * gamma**s\n",
    "        if reached and not_added:\n",
    "            steps_to_goal.append(s)\n",
    "            qs0.append(q0)\n",
    "            qs1.append(q1)\n",
    "            qs2.append(q2)\n",
    "            qs3.append(q3)\n",
    "            qs4.append(q4)\n",
    "            qsS2.append(qS2)\n",
    "            not_added = False\n",
    "        if s > max_steps:\n",
    "            break\n",
    "    if not_added:\n",
    "        steps_to_goal.append(s)\n",
    "        qs0.append(q0)\n",
    "        qs1.append(q1)\n",
    "        qs2.append(q2)\n",
    "        qs3.append(q3)\n",
    "        qs4.append(q4)\n",
    "        qsS2.append(qS2)\n",
    "        not_added = False\n",
    "    qs.append(q)\n",
    "    s = 0\n",
    "    d = start_distance\n",
    "    while(True):\n",
    "        s += 1\n",
    "        step = np.random.normal(0, mean_step)\n",
    "        d = d-step\n",
    "        reached = d < 4\n",
    "        rS = distance(step) + steps(s) + resolution(0,0) + goal(reached) + collision(False)\n",
    "        qS += rS * gamma**s\n",
    "        if reached:\n",
    "            break\n",
    "        if s > max_steps:\n",
    "            break\n",
    "    qsS.append(qS)\n",
    "steps_to_goal = np.log10(steps_to_goal)\n",
    "plt.plot(steps_to_goal, qsc, marker='.', label='Collision')\n",
    "plt.plot(steps_to_goal, qs, marker='.', label='Do Nothing')\n",
    "plt.plot(steps_to_goal, qs0, marker='.', label='Goal pwr=0')\n",
    "plt.plot(steps_to_goal, qs1, marker='.', label='Goal pwr=1')\n",
    "plt.plot(steps_to_goal, qs2, marker='.', label='Goal pwr=2')\n",
    "plt.plot(steps_to_goal, qs3, marker='.', label='Goal pwr=3')\n",
    "plt.plot(steps_to_goal, qs4, marker='.', label='Goal pwr=4')\n",
    "plt.plot(steps_to_goal, qsS, marker='.', label='Steps pwr=0')\n",
    "plt.plot(steps_to_goal, qsS2, marker='.', label='NG pwr=0')\n",
    "#plt.xticks([i for i in range(1,4)])\n",
    "plt.legend(bbox_to_anchor=(1,1))\n",
    "plt.xlabel(f'log_10(# Steps to Goal)')\n",
    "plt.ylabel('Q-Value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb54b2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# play with reward function\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "def distance(d):\n",
    "    #return -1*np.exp(-1*d)\n",
    "    return .1*(np.tanh(d))\n",
    "    #return 0.1*d\n",
    "def steps(s):\n",
    "    return -1\n",
    "def resolution(c1, c2):\n",
    "    return -1*c1#1*(np.exp(-*c1)-1) #+ np.exp(-.5*c2)-1 # two sensors to detect resolution\n",
    "def goal(yes):\n",
    "    return 100 if yes else 0\n",
    "def collision(yes):\n",
    "    return -100 if yes else 0\n",
    "\n",
    "gamma = 0.99\n",
    "start_distance = 100\n",
    "qsc = []\n",
    "qsS2 = []\n",
    "qsS3 = []\n",
    "qsS4 = []\n",
    "qsS5 = []\n",
    "qsS6 = []\n",
    "qsS = []\n",
    "qs = []\n",
    "qs0 = []\n",
    "qs1 = []\n",
    "qs2 = []\n",
    "qs3 = []\n",
    "qs4 = []\n",
    "steps_to_goal = []\n",
    "max_steps = 1000\n",
    "mean_steps = np.arange(.1, 10, .1)\n",
    "for mean_step in mean_steps:\n",
    "    d = start_distance\n",
    "    c = c1 = c2 = 4\n",
    "    s = 0\n",
    "    r = distance(d) + steps(s) + resolution(c1,c2) + goal(False) + collision(False)\n",
    "    rc = distance(d) + steps(s+1) + resolution(c1,c2) + goal(False) + collision(True)\n",
    "    qc = r+gamma*rc\n",
    "    qsc.append(qc)\n",
    "    q = q0 = q1 = q2 = q3 = q4 = qS = qS2 = qS3 = qS4 = qS5 = qS6 = r\n",
    "    not_added = True\n",
    "    while(True):\n",
    "        s += 1\n",
    "        #step = mean_step\n",
    "        step = np.random.normal(mean_step, mean_step)\n",
    "        d = d-step\n",
    "        reached = d < 4\n",
    "        r = distance(0) + steps(s) + resolution(0,0) + goal(False) + collision(False)\n",
    "        r0 = distance(step) + steps(s) + resolution(0,0) + goal(reached) + collision(False)\n",
    "        r1 = distance(step) + steps(s) + resolution(1,1) + goal(reached) + collision(False)\n",
    "        r2 = distance(step) + steps(s) + resolution(2,2) + goal(reached) + collision(False)\n",
    "        r3 = distance(step) + steps(s) + resolution(3,3) + goal(reached) + collision(False)\n",
    "        r4 = distance(step) + steps(s) + resolution(4,4) + goal(reached) + collision(False)\n",
    "        rS2 = distance(step) + steps(s) + resolution(0,0) + goal(False) + collision(False)\n",
    "        rS3 = distance(step) + steps(s) + resolution(1,1) + goal(False) + collision(False)\n",
    "        rS4 = distance(step) + steps(s) + resolution(2,2) + goal(False) + collision(False)\n",
    "        rS5 = distance(step) + steps(s) + resolution(3,3) + goal(False) + collision(False)\n",
    "        rS6 = distance(step) + steps(s) + resolution(4,4) + goal(False) + collision(False)\n",
    "        q += r * gamma**s\n",
    "        q0 += r0 * gamma**s\n",
    "        q1 += r1 * gamma**s\n",
    "        q2 += r2 * gamma**s\n",
    "        q3 += r3 * gamma**s\n",
    "        q4 += r4 * gamma**s\n",
    "        qS2 += rS2 * gamma**s\n",
    "        qS3 += rS3 * gamma**s\n",
    "        qS4 += rS4 * gamma**s\n",
    "        qS5 += rS5 * gamma**s\n",
    "        qS6 += rS6 * gamma**s\n",
    "        if reached and not_added:\n",
    "            steps_to_goal.append(s)\n",
    "            qs0.append(q0)\n",
    "            qs1.append(q1)\n",
    "            qs2.append(q2)\n",
    "            qs3.append(q3)\n",
    "            qs4.append(q4)\n",
    "            qsS2.append(qS2)\n",
    "            qsS3.append(qS3)\n",
    "            qsS4.append(qS4)\n",
    "            qsS5.append(qS5)\n",
    "            qsS6.append(qS6)\n",
    "            not_added = False\n",
    "        if s > max_steps:\n",
    "            break\n",
    "    if not_added:\n",
    "        steps_to_goal.append(s)\n",
    "        qs0.append(q0)\n",
    "        qs1.append(q1)\n",
    "        qs2.append(q2)\n",
    "        qs3.append(q3)\n",
    "        qs4.append(q4)\n",
    "        qsS2.append(qS2)\n",
    "        qsS3.append(qS3)\n",
    "        qsS4.append(qS4)\n",
    "        qsS5.append(qS5)\n",
    "        qsS6.append(qS6)\n",
    "        not_added = False\n",
    "    qs.append(q)\n",
    "    s = 0\n",
    "    d = start_distance\n",
    "    while(True):\n",
    "        s += 1\n",
    "        step = np.random.normal(0, mean_step)\n",
    "        d = d-step\n",
    "        reached = d < 4\n",
    "        rS = distance(step) + steps(s) + resolution(0,0) + goal(reached) + collision(False)\n",
    "        qS += rS * gamma**s\n",
    "        if reached:\n",
    "            break\n",
    "        if s > max_steps:\n",
    "            break\n",
    "    qsS.append(qS)\n",
    "\n",
    "steps_to_goal = np.log10(steps_to_goal)\n",
    "steps_to_goal2 = steps_to_goal.copy()\n",
    "steps_to_goal2.sort()\n",
    "plt.plot(steps_to_goal2, [x for _, x in sorted(zip(steps_to_goal, qsc))], marker='.', label='Collision')\n",
    "plt.plot(steps_to_goal2, [x for _, x in sorted(zip(steps_to_goal, qs))], marker='.', label='Do Nothing')\n",
    "plt.plot(steps_to_goal2, [x for _, x in sorted(zip(steps_to_goal, qs0))], marker='.', label='Goal pwr=0')\n",
    "plt.plot(steps_to_goal2, [x for _, x in sorted(zip(steps_to_goal, qs1))], marker='.', label='Goal pwr=1')\n",
    "plt.plot(steps_to_goal2, [x for _, x in sorted(zip(steps_to_goal, qs2))], marker='.', label='Goal pwr=2')\n",
    "plt.plot(steps_to_goal2, [x for _, x in sorted(zip(steps_to_goal, qs3))], marker='.', label='Goal pwr=3')\n",
    "#plt.plot(steps_to_goal2, [x for _, x in sorted(zip(steps_to_goal, qsc))]qs4, marker='.', label='Goal pwr=4')\n",
    "#plt.plot(steps_to_goal2, [x for _, x in sorted(zip(steps_to_goal, qsc))]qsS, marker='.', label='Steps pwr=0')\n",
    "plt.plot(steps_to_goal2, [x for _, x in sorted(zip(steps_to_goal, qsS2))], marker='.', label='No-Goal pwr=0')\n",
    "plt.plot(steps_to_goal2, [x for _, x in sorted(zip(steps_to_goal, qsS3))], marker='.', label='No-Goal pwr=1')\n",
    "plt.plot(steps_to_goal2, [x for _, x in sorted(zip(steps_to_goal, qsS4))], marker='.', label='No-Goal pwr=2')\n",
    "plt.plot(steps_to_goal2, [x for _, x in sorted(zip(steps_to_goal, qsS5))], marker='.', label='No-Goal pwr=3')\n",
    "#plt.plot(steps_to_goal2, [x for _, x in sorted(zip(steps_to_goal, qsc))]qsS6, marker='.', label='NG pwr=4')\n",
    "#plt.xticks([i for i in range(1,4)])\n",
    "plt.title('Random Walk')\n",
    "#plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.1),\n",
    "#          fancybox=True, shadow=True, ncol=3)\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.xlabel(r'$log_{10}$(# Steps to Goal)')\n",
    "plt.ylabel('Q-Value')\n",
    "#plt.yticks([-300, -200, -100, 0, 100])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e44c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_to_goal"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
